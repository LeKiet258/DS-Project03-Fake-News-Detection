{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link trang web: https://share.streamlit.io/lekiet258/project03_ds/app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BẢNG PHÂN CÔNG\n",
    "\n",
    "| MSSV     | Họ và tên        | % đóng góp (tối đa 100%) | Chi   tiết công việc         |\n",
    "|----------|------------------|--------------------------|------------------------------|\n",
    "| 19120511 | Võ Văn Hiếu      | 100                      | Tiền xử lý tiếng Việt + mô hình Rain Forest                         |\n",
    "| 19120526 | Huỳnh Đức Huy    | 100                      | Mô hình Decision Tree + code/deploy trang Web                        |\n",
    "| 19120539 | Vương Thế Khang  | 100                      | EDA (Khám phá dữ liệu) + code Streamlit                         |\n",
    "| 19120554 | Lê Kiệt          | 100                      | Mô hình Linear Regression Web + Soạn báo cáo                       |\n",
    "| 19120586 | Nguyễn Phát Minh | 100                      | Mô hình Logistic Regression + xây dựng Pipeline quá trình huấn luyện                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THƯ VIỆN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: trong Project nhóm có sử dụng thư viện `underthesea`. Nếu thầy cô chưa có thư viện này có thể tháo comment cell phía dưới để cài đặt thư viện\n",
    "* Link tham khảo: https://underthesea.readthedocs.io/en/latest/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import requests\n",
    "\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. KHÁM PHÁ DỮ LIỆU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc dữ liệu từ file \"vn_news_223_tdlft.csv\" và lưu vào dataframe `news_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n",
       "      <td>binhluan.biz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thủ tướng Nhật cúi đầu xin lỗi vì tinh thần ph...</td>\n",
       "      <td>www.ipick.vn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Choáng! Cơ trưởng đeo khăn quàng quẩy banh nóc...</td>\n",
       "      <td>tintucqpvn.net</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chưa bao giờ nhạc Kpop lại dễ hát đến thế!!!\\r...</td>\n",
       "      <td>tintucqpvn.net</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Đại học Hutech sẽ áp dụng cải cách \"Tiếq Việt\"...</td>\n",
       "      <td>www.gioitreviet.net</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               domain  \\\n",
       "0  Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...         binhluan.biz   \n",
       "1  Thủ tướng Nhật cúi đầu xin lỗi vì tinh thần ph...         www.ipick.vn   \n",
       "2  Choáng! Cơ trưởng đeo khăn quàng quẩy banh nóc...       tintucqpvn.net   \n",
       "3  Chưa bao giờ nhạc Kpop lại dễ hát đến thế!!!\\r...       tintucqpvn.net   \n",
       "4  Đại học Hutech sẽ áp dụng cải cách \"Tiếq Việt\"...  www.gioitreviet.net   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_csv('vn_news_223_tdlfr.csv')\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu có bao nhiều dòng và bao nhiêu cột?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy dữ liệu có kích thước **223 dòng x 3 cột**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mỗi dòng có ý nghĩa gì? Có vấn đề các dòng có ý nghĩa khác nhau không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan sát sơ bộ dữ liệu ta thấy mỗi dòng chứa thông tin về một bài báo, có vẻ như không có vấn đề các dòng có ý nghĩa khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu có các dòng bị lặp không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiểm tra xem dữ liệu có các dòng bị lặp không và lưu kết quả vào biến `have_duplicated_row`. Biến này sẽ có giá trị True nếu dữ liệu có các dòng bị lặp và có giá trị False nếu ngược lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_duplicated_row = all(news_df.duplicated())\n",
    "have_duplicated_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy, không có dòng nào bị lặp lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mỗi cột có ý nghĩa gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông tin về các cột như sau:\n",
    "- **text:** nội dung của bài báo\n",
    "- **domain:** tên miền (website)\n",
    "- **label:** nhãn (1: tin giả, 0: tin thật)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mỗi cột hiện đang có kiểu dữ liệu gì? Có cột nào có kiểu dữ liệu chưa phù hợp để có thể xử lý tiếp không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thử kiểu dữ liệu của các cột dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      object\n",
       "domain    object\n",
       "label      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\to$ Có vẻ các cột đều có kiểu dữ liệu phù hợp. Nếu trong quá trình phân tích dữ liệu cần phải thay đổi kiểu dữ liệu của các cột thì ta sẽ quay lại tiền xử lý ở đây, tạm thời ta chấp nhận kiểu dữ liệu hiện tại của các cột."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiểm tra phân bố các lớp/nhãn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cột `label` có 2 giá trị 1 hoặc 0. Ta sẽ xem phân bố của 2 nhãn này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['label'].value_counts().plot.bar(xlabel = 'label', ylabel = 'frequency', rot = 0, color = 'maroon');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\to$ Phân bố 2 nhãn không quá chênh lệch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các thông tin thống kê của văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các thông tin thống kê bao gồm:\n",
    "- Chiều dài trung bình của mỗi record.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiều dài trung bình của các text: 2555.0\n"
     ]
    }
   ],
   "source": [
    "print('Chiều dài trung bình của các text:', news_df['text'].apply(len).mean().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. TIỀN XỬ LÝ VĂN BẢN TIẾNG VIỆT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở phần này, ta tiền xử lý văn bản cho cột `text` để chuẩn bị cho pipeline xử lý lúc sau. Mỗi phần tử trong pipeline là 1 class \"transformer\" nên để làm việc với pipeline lúc sau, định nghĩa 1 class \"transformer\" `TextReducer` thừa kế 2 class `BaseEstimator`, `TransformerMixin` dùng để tiền xử lý văn bản tiếng Việt với 3 phương thức\n",
    "- **init()**: trong đây lưu trữ danh sách các stopwords được lấy từ [link stopwords](https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords.txt). Danh sách được lưu vào `self.stopwords`\n",
    "- **fit()**: nhận 2 tham số X là 1 danh sách các đoạn text, y là danh sách label. Tuy nhiên trong ngữ cảnh này ta sẽ không tùy chỉnh hàm fit mà trả về chính nó (self) luôn\n",
    "- **transform()**: nhận 1 tham số X là danh sách các đoạn text cần tiền xử lý, trả về 1 Series các đoạn text đã qua tiền xử lý. Trong hàm này, tiền xử lý văn bản tiếng Việt theo các bước sau: \n",
    "    - Bước 1: loại bỏ các đường dẫn URL (Ví dụ: http, https)\n",
    "    - Bước 2: loại bỏ ký tự đặc biệt ([@#/!.\\'‘’\\\"“”–+-=()%) và thay dấu dấu xuống hàng (\\r\\n) thành dấu cách\n",
    "    - Bước 3: đổi các đoạn text đang có cả chữ hoa và chữ thường thành toàn bộ chữ thường\n",
    "    - Bước 4: tokenize các đoạn văn bản để với mỗi văn bản chỉ còn là danh sách các từ khóa nội dung của từng văn bản đó. Nhóm quyết định sử dụng hàm `word_tokenize` của thư viện `underthesea` để tokenize các từ tiếng Việt\n",
    "    - Bước 5: loại bỏ stopwords dựa vào danh sách stopwords đã lưu vào `self.stopwords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextReducer(BaseEstimator, TransformerMixin):\n",
    "    stopwords_raw_url = \"https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords.txt\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stopwords = requests.get(self.stopwords_raw_url).text.split('\\n')\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        _X = pd.Series(X)\n",
    "\n",
    "        # Bước 1\n",
    "        _X = _X.apply(lambda text: re.sub(r'http(s?)\\S+.', '', text))\n",
    "        # Bước 2\n",
    "        _X = _X.apply(lambda text: re.sub(r'[@#/!.\\'‘’\\\"“”–+-=()%]', '', text))\n",
    "        _X = _X.apply(lambda text: re.sub(r'\\r\\n', ' ', text))\n",
    "        # Bước 3\n",
    "        _X = _X.apply(lambda text: text.lower())\n",
    "        # Bước 4\n",
    "        _X = _X.apply(word_tokenize)\n",
    "        # Bước 5\n",
    "        _X = _X.apply(lambda words: ' '.join([word for word in words if word not in self.stopwords]))\n",
    "\n",
    "        return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. MÔ HÌNH HÓA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở phần này, nhóm sử dụng 2 mô hình tuyến tính (Linear Regression và Logistic Regression) + 2 mô hình phi tuyến (Random Forest và Decision Tree). Để sử dụng dữ liệu văn bản cho mô hình dự đoán, văn bản phải được phân tích cú pháp để loại bỏ một số từ nhất định(chính là bước tiền xử lý tiếng Việt ở trên). Sau đó, những từ này cần được mã hóa dưới dạng số nguyên hoặc giá trị dấu phẩy động, để sử dụng làm đầu vào trong thuật toán học máy. Quá trình này được gọi là **trích xuất đặc trưng** (hay vectơ hóa/vectorize). Như vậy, với mỗi mô hình, sử dụng 2 vectorizer khác nhau:\n",
    "- `CountVectorizer()`: dủng để tính tần số xuất hiện của từng token trong văn bản (token có thể là 1 từ hoặc nhiều từ - đã có ở bước tokenize trong tiền xử lý văn bản tiếng Việt) \n",
    "- `TfidfVectorizer()`: dùng để tính độ quan trọng (tf-idf) của từng token trong văn bản. Những token có giá trị tf-idf cao là những token xuất hiện nhiều trong văn bản này và xuất hiện ít trong các văn bản khác. Việc này giúp lọc ra những từ phổ biến và giữ lại những từ có giá trị cao (từ khoá của văn bản đó)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để thuận tiện cho việc gọi hàm ở cell sau đó (vì 4 mô hình x 2 vectorizer = 8 mô hình nên nếu không dùng hàm sẽ rất bất tiện và dài dòng), tại cell này làm những công việc sau:\n",
    "- Lưu 4 mô hình vào dictionary `classifiers` với 4 key là tên viết tắt của tên mô hình như code\n",
    "- Lưu 2 vectorizer vào dictionary `vectorizers`, cách viết key tương tự như của biến `classifiers`\n",
    "- Lưu class TextReducer dùng để tiền xử lý văn bản tiếng Việt vào dictionary 1 phần tử `preprocessors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessors = {'tr':TextReducer()}\n",
    "\n",
    "vectorizers = {'cv':CountVectorizer(), \n",
    "               'tv':TfidfVectorizer()}\n",
    "\n",
    "classifiers = {'li':LinearRegression(), \n",
    "               'lo':LogisticRegression(random_state=42), \n",
    "               'dt':DecisionTreeClassifier(random_state=42), \n",
    "               'rf':RandomForestClassifier(random_state=42)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Định nghĩa hàm `generate_models` nhận các tham số \n",
    "- `preprocessors`, `vectorizers`, `classifiers`: chính là 3 dictionary ở cell phía trên\n",
    "- `X_train`, `y_train`: bộ dữ liệu huấn luyện. Trong đó y_train là Series 1 cột thể hiện nhãn 1 hoặc 0 và X_train là 1 dataframe có\n",
    "2 cột text, domain\n",
    "- `out`: tên **folder** dùng để lưu các file mô hình (file nhị phân có đuôi .pkl) \n",
    "\n",
    "Công việc của hàm `generate_models`: \n",
    "- Lần lượt nhóm từng phương thức vector hóa trong `vectorizers` với từng mô hình trong `classifiers` (do hiện tại `preprocessors` chỉ có 1 phần tử nên không quan trọng lắm). Với mỗi lần nhóm:\n",
    "    - Tạo ra pipeline gồm 3 bước: tiền xử lý + vector hóa + mô hình phân lớp\n",
    "    - Tiến hành fit tập dữ liệu train vào pipeline vừa tạo\n",
    "    - Dự đoán nhãn cho tập train và tính độ đo accuracy giữa kết quả dự đoán (y_pred) và kết quả train (y_train). Độ đo này là 1 số thực trong khoảng [0%, 100%] và được lưu kèm với tên mô hình trong biến kết quả trả về tên là `accuracies` (tức `accuracies` là 1 dict có `key` là tên mô hình và `val` là độ chính xác accuracy_score giữa y_pred và y_train). Mục đích là để đánh giá từng mô hình  \n",
    "    - Lưu mô hình vừa huấn luyện vào file nhị phân .pkl. file này được đặt tên: \n",
    "    \n",
    "      **<preprocessor sử dụng>\\_<vectorizer sử dụng>_<classifier sử dụng>**.pkl\\. Trong đó:\n",
    "\n",
    "      |                      | Viết tắt                                                                                       |\n",
    "      |----------------------|------------------------------------------------------------------------------------------------|\n",
    "      | preprocessor sử dụng | tr = Text Reducer                                                                              |\n",
    "      | vectorizer sử dụng   | cv = Count Vectorizer<br>tv = Tfidf Vectorizer                                                 |\n",
    "      | classifier sử dụng   | li = Linear Regression<br>lo = Logistic Regression<br>dt = Decision Tree<br>rf = Random Forest |\n",
    "\n",
    "<p>\n",
    "\n",
    "- **Lưu ý**: khi gọi hàm `accuracy_score` để tính độ chính xác giữa y_train và y_test trên mô hình Linear Regression sẽ bị lỗi \"<font color='red'>Classification metrics can't handle a mix of binary and continuous targets</font>\". Đó là do kết quả thực tế y_train là **binary outcome** (tức 0 và 1), còn mô hình Linear Regression dự đoán y_pred ra các giá trị số thực và các giá trị này cực kỳ gần 0 (VD: 9.99999e-18 ~ 0) hoặc gần 1 (VD: 1.000000001 ~ 1). Và lỗi này chỉ xảy ra với mô hình Linear Regression nên ta sẽ try..catch để khi có lỗi, chỉ cần làm tròn số về 1 hoặc 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_models(preprocessors, vectorizers, classifiers, X_train, y_train, out):\n",
    "    accuracies = dict()\n",
    "    \n",
    "    for p in preprocessors:\n",
    "        for v in vectorizers:\n",
    "            for c in classifiers:\n",
    "                pipeline = Pipeline([('text_reducer', preprocessors[p]),\n",
    "                                     ('vectorizer'  , vectorizers[v]),\n",
    "                                     ('classifier'  , classifiers[c])])\n",
    "                # train mô hình\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                \n",
    "                # lưu kết quả dự đoán để đánh giá mô hình\n",
    "                y_pred = pipeline.predict(X_train)\n",
    "                try:\n",
    "                    acc = accuracy_score(y_train, y_pred) * 100\n",
    "                except:\n",
    "                    acc = accuracy_score(y_train, y_pred.round()) * 100\n",
    "                accuracies[p + '_' + v + '_' + c] = acc\n",
    "                \n",
    "                # lưu mô hình vào file .pkl\n",
    "                filepath = out.rstrip('\\\\').rstrip('/') + '/' + p + '_' + v + '_' + c + '.pkl'\n",
    "                joblib.dump(pipeline, filepath, compress = 1)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = news_df['text']\n",
    "y_train = news_df['label']\n",
    "\n",
    "train_accuracies = generate_models(preprocessors, vectorizers, classifiers, X_train, y_train, 'models')\n",
    "train_accuracies # chạy khoảng 4p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Đánh giá mô hình: Vì sử dụng toàn bộ tập train làm tập test, thêm nữa tập train có khá ít dữ liệu nên hầu hết các mô hình (kèm với vectorizer tương ứng) đều cho kết quả dự đoán đúng là 100%, ngoại trừ mô hình Logistic Regression với tfidf vectorizer chỉ đoán đúng khoảng 97% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Deploy mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Phần này sử dụng thư viện Streamlit và làm trong file `app.py`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
